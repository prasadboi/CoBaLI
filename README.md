# CoBaLI
Continuous Batching for LLM inference
