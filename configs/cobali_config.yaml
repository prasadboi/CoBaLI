# CoBaLI Configuration - Full System
# Phase 3: Continuous batching + Prefill splitting

model:
  path: "models/qwen2-0_5b-instruct-q4_0.gguf"
  n_gpu_layers: -1
  n_ctx: 2048

batching:
  enable_continuous_batching: true
  max_batch_size: 32
  max_tokens_per_batch: 4096

prefill_splitting:
  enabled: true
  chunk_size: 512
  decode_priority_weight: 0.7  # 0.0-1.0, higher = prioritize decode

memory:
  kv_cache_size_mb: 4096
  max_concurrent_requests: 64

performance:
  num_threads: 8
  use_mmap: true
  use_mlock: false

scheduling:
  policy: 0  # 0=FCFS, 1=Priority, 2=Fair
  preemption_mode: 0  # 0=None, 1=Recompute, 2=Swap

logging:
  verbose: true
  log_file: ""

