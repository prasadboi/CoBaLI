You are a helpful assistant. Summarize the pros and cons of continuous (iteration-level) batching for LLM serving. 
Cover effects on TTFT (time to first token), throughput under load, and fairness across short vs. long prompts. 
Conclude with two scenarios where sequential (run-to-completion) may still be preferred.
